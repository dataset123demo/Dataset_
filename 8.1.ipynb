{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c4f922-cc3a-47b5-b59f-988e53815905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0, Output: [[-1.0806972]]\n",
      "Time step 1, Output: [[-1.4798803]]\n",
      "Time step 2, Output: [[-0.1047624]]\n",
      "Time step 3, Output: [[-1.27035141]]\n",
      "Time step 4, Output: [[-2.5942887]]\n",
      "Time step 5, Output: [[0.17676479]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bonde\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - loss: 4.8050\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 4.6707\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - loss: 4.5376\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: 4.4057\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 4.2751\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step - loss: 4.1459\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 4.0182\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 3.8919\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 3.7673\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - loss: 3.6443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "[[0.7400064]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Activation functions and derivatives\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Initialize weights\n",
    "Wxh = np.random.randn(10, 5)  # Input to hidden weights\n",
    "Whh = np.random.randn(10, 10) # Hidden to hidden weights\n",
    "Why = np.random.randn(1, 10)  # Hidden to output weights\n",
    "\n",
    "bh = np.zeros((10, 1))        # Hidden bias\n",
    "by = np.zeros((1, 1))         # Output bias\n",
    "\n",
    "# Initial hidden state\n",
    "h = np.zeros((10, 1))\n",
    "\n",
    "# Forward pass\n",
    "def rnn_step(X, h):\n",
    "    h = sigmoid(np.dot(Wxh, X) + np.dot(Whh, h) + bh)  # Update hidden state\n",
    "    y = np.dot(Why, h) + by  # Compute output\n",
    "    return h, y\n",
    "\n",
    "# Dummy input sequence\n",
    "X = [np.random.randn(5, 1) for _ in range(6)]  # 6 time steps of 5-dimensional input\n",
    "\n",
    "# Process each time step\n",
    "for t in range(len(X)):\n",
    "    h, y = rnn_step(X[t], h)\n",
    "    print(f\"Time step {t}, Output: {y}\")\n",
    "\n",
    "# Define a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an RNN layer (input_size = 5, hidden_size = 10)\n",
    "model.add(SimpleRNN(10, input_shape=(None, 5)))\n",
    "\n",
    "# Add a Dense output layer\n",
    "model.add(Dense(1))  # output_size = 1\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Generate dummy data\n",
    "X = tf.random.normal([1, 6, 5])  # (batch_size, sequence_length, input_size)\n",
    "y = tf.random.normal([1, 1])     # (batch_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10)\n",
    "\n",
    "# Predict using the model\n",
    "output = model.predict(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79903a-8136-4f20-9aa3-ae66297c24d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a4a3f-8a96-49ca-ae69-a6c10ac69913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fc6dcc-3052-4992-a7a5-3d99742e2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.1853, Accuracy: 0.4000\n",
      "Epoch 50, Loss: 0.8259, Accuracy: 0.8000\n",
      "Epoch 100, Loss: 0.1862, Accuracy: 1.0000\n",
      "Epoch 150, Loss: 0.6116, Accuracy: 0.8000\n",
      "Epoch 200, Loss: 1.6040, Accuracy: 0.8000\n",
      "Epoch 250, Loss: 0.2041, Accuracy: 0.8000\n",
      "Epoch 300, Loss: 1.3879, Accuracy: 0.4000\n",
      "Epoch 350, Loss: 1.2931, Accuracy: 0.8000\n",
      "Epoch 400, Loss: 1.7327, Accuracy: 0.4000\n",
      "Epoch 450, Loss: 1.5268, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Build Recurrent Neural Network by Using the Numpy Library\n",
    "import numpy as np\n",
    "\n",
    "# RNN configuration\n",
    "input_dim = 1\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "sequence_length = 5\n",
    "num_epochs = 500\n",
    "\n",
    "# Initial weights and biases\n",
    "weight_input_hidden = np.random.randn(hidden_dim, input_dim) * 0.01\n",
    "weight_hidden_hidden = np.random.randn(hidden_dim, hidden_dim) * 0.01\n",
    "weight_hidden_output = np.random.randn(output_dim, hidden_dim) * 0.01\n",
    "\n",
    "bias_hidden = np.zeros((hidden_dim, 1))\n",
    "bias_output = np.zeros((output_dim, 1))\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_derivative(output):\n",
    "    return output * (1 - output)\n",
    "    \n",
    "# Forward pass\n",
    "def forward_step(input_t, hidden_state_prev):\n",
    "    hidden_state = sigmoid(np.dot(weight_input_hidden, input_t) + np.dot(weight_hidden_hidden, hidden_state_prev) + bias_hidden)\n",
    "    output = np.dot(weight_hidden_output, hidden_state) + bias_output\n",
    "    return output, hidden_state\n",
    "    \n",
    "# Backpropagation Through Time (BPTT)\n",
    "def bptt(inputs, targets, initial_hidden_state):\n",
    "    global weight_input_hidden, weight_hidden_hidden, weight_hidden_output, bias_hidden, bias_output\n",
    "    \n",
    "    # Initialize gradients\n",
    "    grad_weight_input_hidden = np.zeros_like(weight_input_hidden)\n",
    "    grad_weight_hidden_hidden = np.zeros_like(weight_hidden_hidden)\n",
    "    grad_weight_hidden_output = np.zeros_like(weight_hidden_output)\n",
    "    grad_bias_hidden = np.zeros_like(bias_hidden)\n",
    "    grad_bias_output = np.zeros_like(bias_output)\n",
    "    grad_hidden_state_next = np.zeros_like(initial_hidden_state)\n",
    "    \n",
    "    # Store hidden states and outputs\n",
    "    hidden_states, predicted_outputs = [np.copy(initial_hidden_state)], []\n",
    "    \n",
    "    # Forward pass through each time step\n",
    "    hidden_state = initial_hidden_state\n",
    "    for input_t in inputs:\n",
    "        output, hidden_state = forward_step(input_t, hidden_state)\n",
    "        predicted_outputs.append(output)\n",
    "        hidden_states.append(hidden_state)\n",
    "    \n",
    "    # Backward pass through time\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        output_error = predicted_outputs[t] - targets[t]\n",
    "        grad_weight_hidden_output += np.dot(output_error, hidden_states[t].T)\n",
    "        grad_bias_output += output_error\n",
    "        hidden_state_error = np.dot(weight_hidden_output.T, output_error) + grad_hidden_state_next\n",
    "        hidden_state_delta = sigmoid_derivative(hidden_states[t]) * hidden_state_error\n",
    "        grad_bias_hidden += hidden_state_delta\n",
    "        grad_weight_input_hidden += np.dot(hidden_state_delta, inputs[t].T)\n",
    "        grad_weight_hidden_hidden += np.dot(hidden_state_delta, hidden_states[t-1].T)\n",
    "        grad_hidden_state_next = np.dot(weight_hidden_hidden.T, hidden_state_delta)\n",
    "    \n",
    "    # Gradient clipping and parameter update\n",
    "    for grad in [grad_weight_input_hidden, grad_weight_hidden_hidden, grad_weight_hidden_output, grad_bias_hidden, grad_bias_output]:\n",
    "        np.clip(grad, -1, 1, out=grad)\n",
    "        \n",
    "    weight_input_hidden -= learning_rate * grad_weight_input_hidden\n",
    "    weight_hidden_hidden -= learning_rate * grad_weight_hidden_hidden\n",
    "    weight_hidden_output -= learning_rate * grad_weight_hidden_output\n",
    "    bias_hidden -= learning_rate * grad_bias_hidden\n",
    "    bias_output -= learning_rate * grad_bias_output\n",
    "    \n",
    "    return predicted_outputs, targets\n",
    "    \n",
    "# Accuracy Calculation\n",
    "def calculate_accuracy(predicted_outputs, targets):\n",
    "    correct_predictions = 0\n",
    "    for y_pred, y_true in zip(predicted_outputs, targets):\n",
    "        # Assuming a simple threshold to classify outputs\n",
    "        predicted_label = 1 if y_pred > 0.5 else 0\n",
    "        true_label = 1 if y_true > 0.5 else 0\n",
    "        correct_predictions += (predicted_label == true_label)\n",
    "    return correct_predictions / len(targets)\n",
    "# Training\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    initial_hidden_state = np.zeros((hidden_dim, 1))\n",
    "    inputs = [np.random.randn(input_dim, 1) for _ in range(sequence_length)]\n",
    "    targets = [np.random.randn(output_dim, 1) for _ in range(sequence_length)]\n",
    "    \n",
    "    predicted_outputs, targets = bptt(inputs, targets, initial_hidden_state)\n",
    "    \n",
    "    # Calculate loss (mean squared error)\n",
    "    loss = np.mean((np.array(targets) - np.array(predicted_outputs)) ** 2)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = calculate_accuracy(predicted_outputs, targets)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad0aca-4525-48e5-b3c1-db48fd4e8a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
